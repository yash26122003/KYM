##########################################
# The compas dataset conversation config
##########################################

# the parsing model: {ucinlp/compas-t5-small, ucinlp/compas-t5-large}
ExplainBot.parsing_model_name = "ucinlp/compas-t5-small"

# set skip_prompts to true for quicker startup for finetuned models
# make sure to set to false using few-shot models
ExplainBot.skip_prompts = True

ExplainBot.t5_config = "./parsing/t5/gin_configs/t5-large.gin"
ExplainBot.seed = 0
ExplainBot.background_dataset_file_path = "./data/compas_train.csv"
ExplainBot.model_file_path = "./data/compas_model_grad_boosted_tree.pkl"
ExplainBot.dataset_file_path = "./data/compas_test.csv"

ExplainBot.name = "compas"

ExplainBot.dataset_index_column = 0
ExplainBot.target_variable_name = "y"
ExplainBot.categorical_features = None
ExplainBot.numerical_features = None
ExplainBot.remove_underscores = True

ExplainBot.prompt_metric = "cosine"
ExplainBot.prompt_ordering = "ascending"

# Prompt params
Prompts.prompt_cache_size = 1_000_000
Prompts.prompt_cache_location = "./cache/compas-prompts.pkl"
Prompts.max_values_per_feature = 2
Prompts.sentence_transformer_model_name = "all-mpnet-base-v2"
Prompts.prompt_folder = "./explain/prompts"

Prompts.num_per_knn_prompt_template = 1
Prompts.num_prompt_template = 7

# Explanation Params
Explanation.max_cache_size = 1_000_000

# MegaExplainer Params
MegaExplainer.cache_location = "./cache/compas-mega-explainer-tabular.pkl"
MegaExplainer.use_selection = False

# Conversation params
Conversation.class_names = {0: "likely to commit a crime", 1: "unlikely to commit a crime"}

# Tabular dice params
TabularDice.cache_location = "./cache/compas-dice-tabular.pkl"

# Dataset description
DatasetDescription.dataset_objective = "predict whether someone will commit a crime"
DatasetDescription.dataset_description = "recidivism prediction"
DatasetDescription.model_description = "gradient boosted tree"
